% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deepregression.R
\name{deepregression_init}
\alias{deepregression_init}
\title{Initializing Deep Distributional Regression Models}
\usage{
deepregression_init(
  n_obs,
  ncol_structured,
  ncol_deep,
  list_structured,
  list_deep,
  use_bias_in_structured = FALSE,
  nr_params = 2,
  lss = TRUE,
  train_together = NULL,
  lambda_lasso = NULL,
  lambda_ridge = NULL,
  family,
  dist_fun = NULL,
  variational = TRUE,
  weights = NULL,
  learning_rate = 0.01,
  optimizer = optimizer_adam(lr = learning_rate),
  monitor_metric = list(),
  posterior = posterior_mean_field,
  prior = prior_trainable,
  orthog_fun = orthog,
  orthogX = NULL,
  kl_weight = 1/n_obs,
  output_dim = 1,
  mixture_dist = FALSE,
  split_fun = split_model,
  ind_fun = function(x) x,
  extend_output_dim = 0,
  offset = NULL,
  additional_penalty = NULL,
  constraint_fun = NULL,
  compile_model = TRUE
)
}
\arguments{
\item{n_obs}{number of observations}

\item{ncol_structured}{a vector of length #parameters
defining the number of variables used for each of the parameters.
If any of the parameters is not modelled using a structured part
the corresponding entry must be zero.}

\item{ncol_deep}{a vector of length #parameters
defining the number of variables used for each of the parameters.
If any of the parameters is not modelled using a deep part
the corresponding entry must be zero. If all parameters
are estimated by the same deep model, the first entry must be
non-zero while the others must be zero.}

\item{list_structured}{list of (non-linear) structured layers
(list length between 0 and number of parameters)}

\item{list_deep}{list of deep models to be used
(list length between 0 and number of parameters)}

\item{use_bias_in_structured}{logical, whether or not to use a bias in
structured layer}

\item{nr_params}{number of distribution parameters}

\item{lss}{whether or not to model the whole distribution
(lss in the style of location, scale and shape approaches)}

\item{train_together}{see \code{?deepregression}}

\item{lambda_lasso}{penalty parameter for l1 penalty of structured layers}

\item{lambda_ridge}{penalty parameter for l2 penalty of structured layers}

\item{family}{family specifying the distribution that is modelled}

\item{dist_fun}{a custom distribution applied to the last layer,
see \code{\link{make_tfd_dist}} for more details on how to construct
a custom distribution function.}

\item{variational}{logical value specifying whether or not to use
variational inference. If \code{TRUE}, details must be passed to
the via the ellipsis to the initialization function}

\item{weights}{observation weights used in the likelihood}

\item{learning_rate}{learning rate for optimizer}

\item{optimizer}{optimizer used (defaults to adam)}

\item{monitor_metric}{see \code{?deepregression}}

\item{posterior}{function defining the posterior}

\item{prior}{function defining the prior}

\item{orthog_fun}{function defining the orthogonalization}

\item{orthogX}{vector of columns defining the orthgonalization layer}

\item{kl_weight}{KL weights for variational networks}

\item{output_dim}{dimension of the output (> 1 for multivariate outcomes)}

\item{mixture_dist}{see \code{?deepregression}}

\item{split_fun}{see \code{?deepregression}}

\item{ind_fun}{see \code{?deepregression}}

\item{extend_output_dim}{see \code{?deepregression}}

\item{offset}{list of logicals corresponding to the paramters;
defines per parameter if an offset should be added to the predictor}

\item{additional_penalty}{to specify any additional penalty, provide a function
that takes the \code{model$trainable_weights} as input and applies the
additional penalty. In order to get the correct index for the trainable
weights, you can run the model once and check its structure.}

\item{constraint_fun}{function; a constraint for the linear layers}

\item{compile_model}{logical; whether to compile the model (default is TRUE)}
}
\description{
Initializing Deep Distributional Regression Models
}
